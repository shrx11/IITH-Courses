{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q3-code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qeKpGWlXT7I"
      },
      "source": [
        "# Assign 1 Code Skeleton\n",
        "# Please use this outline to implement your decision tree. You can add any code around this.\n",
        "\n"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eGQ8dxMXXBy"
      },
      "source": [
        "import csv\n",
        "\n",
        "# Enter You Name Here\n",
        "myname = \"Sharanya\" \n"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79vJVlQQXXEC",
        "outputId": "b394534c-0b4f-4c4f-f4eb-0789a5416539"
      },
      "source": [
        "# Load data set\n",
        "with open(\"/content/wine-dataset.csv\") as f:\n",
        "  next(f, None)\n",
        "  data = [tuple(line) for line in csv.reader(f, delimiter=\",\")]\n",
        "\n",
        "\n",
        "print (\"Number of records: %d\" % len(data))\n",
        " "
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of records: 4898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5yOB69oYBKv"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oVbTuQYXXGm"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from pprint import pprint"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J20LZc7tXXJN"
      },
      "source": [
        "df=pd.read_csv(\"/content/wine-dataset.csv\")\n",
        "df=df.rename(columns={\"quality\":\"label\"})"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCkWFXZcXXR4"
      },
      "source": [
        "def train_test_split(df,test_ratio):                        #splitting train and test data\n",
        "\n",
        "  test_size=round(test_ratio*len(df))\n",
        "\n",
        "  indices=df.index.tolist()\n",
        "  test_indices=random.sample(population=indices,k=test_size)\n",
        "\n",
        "  test_df=df.loc[test_indices]\n",
        "  train_df=df.drop(test_indices)\n",
        "\n",
        "  return train_df,test_df"
      ],
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io9WBnK1JHDv"
      },
      "source": [
        "#random.seed(0)\n",
        "train_df,test_df=train_test_split(df,test_ratio=0.1)"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH8FSzbzXXUk"
      },
      "source": [
        "data = train_df.values        "
      ],
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkkdLn-RXXaW"
      },
      "source": [
        "def check_purity(data):                 #function to check purity \n",
        "  label_column=data[:,-1]\n",
        "  unique_classes=np.unique(label_column)\n",
        "\n",
        "  if len(unique_classes)==1:\n",
        "    return True\n",
        "  else:\n",
        "    return False\n"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3epy9dUXXf1"
      },
      "source": [
        "def classify_data(data):\n",
        "\n",
        "  label_column=data[:,-1]\n",
        "  unique_classes, counts_unique_classes=np.unique(label_column, return_counts=True)\n",
        "\n",
        "  index=counts_unique_classes.argmax()\n",
        "  classification=unique_classes[index]\n",
        "\n",
        "  return classification"
      ],
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRaYOCpgXXiZ"
      },
      "source": [
        "def get_potential_splits(data):             #calculating all potential splits in the data colunm wise and storing in  a vector\n",
        "    \n",
        "    potential_splits = {}\n",
        "    _, n_columns = data.shape\n",
        "    for column_index in range(n_columns - 1):        # excluding the last column which is the label\n",
        "        potential_splits[column_index] = []\n",
        "        values = data[:, column_index]\n",
        "        unique_values = np.unique(values)\n",
        "\n",
        "        for index in range(len(unique_values)):\n",
        "            if index != 0:\n",
        "                current_value = unique_values[index]\n",
        "                previous_value = unique_values[index - 1]\n",
        "                potential_split = (current_value + previous_value) / 2\n",
        "                \n",
        "                potential_splits[column_index].append(potential_split)\n",
        "    \n",
        "    return potential_splits"
      ],
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZiPrgzDXXli"
      },
      "source": [
        "def split_data(data, split_column, split_value):          #function to split data at each decision\n",
        "    \n",
        "    split_column_values = data[:, split_column]\n",
        "\n",
        "    data_below = data[split_column_values <= split_value]\n",
        "    data_above = data[split_column_values >  split_value]\n",
        "    \n",
        "    return data_below, data_above"
      ],
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ1QWJ9nXXoO"
      },
      "source": [
        "def calculate_entropy(data):                                  #function to calculate entropy of node in the tree\n",
        "    \n",
        "    label_column = data[:, -1]\n",
        "    _, counts = np.unique(label_column, return_counts=True)\n",
        "\n",
        "    probabilities = counts / counts.sum()\n",
        "    entropy = sum(probabilities * -np.log2(probabilities))\n",
        "     \n",
        "    return entropy"
      ],
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bM-BbXN3pRX"
      },
      "source": [
        "def calculate_overall_entropy(data_below, data_above):\n",
        "    \n",
        "    n = len(data_below) + len(data_above)\n",
        "    if n==0:\n",
        "      return 0;\n",
        "    p_data_below = len(data_below) / n\n",
        "    p_data_above = len(data_above) / n\n",
        "\n",
        "    overall_entropy =  (p_data_below * calculate_entropy(data_below) \n",
        "                      + p_data_above * calculate_entropy(data_above))\n",
        "    \n",
        "    return overall_entropy"
      ],
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSqtUMRx3pTw"
      },
      "source": [
        "def determine_best_split(data, potential_splits):                     #selecting the best split by checking information gain\n",
        "    \n",
        "    overall_entropy = 9999\n",
        "    for column_index in potential_splits:\n",
        "        for value in potential_splits[column_index]:\n",
        "            data_below, data_above = split_data(data, split_column=column_index, split_value=value)\n",
        "            current_overall_entropy = calculate_overall_entropy(data_below, data_above)\n",
        "\n",
        "            if current_overall_entropy <= overall_entropy:\n",
        "                overall_entropy = current_overall_entropy\n",
        "                best_split_column = column_index\n",
        "                best_split_value = value\n",
        "    \n",
        "    return best_split_column, best_split_value\n",
        "\n"
      ],
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfWLIK1i3pWo"
      },
      "source": [
        "def decision_tree_algorithm(df, counter=0, min_samples=2, max_depth=10):      #recursive decision tree algorithm\n",
        "    \n",
        "    # data preparations\n",
        "    if counter == 0:\n",
        "        global COLUMN_HEADERS\n",
        "        COLUMN_HEADERS = df.columns\n",
        "        data = df.values\n",
        "    else:\n",
        "        data = df           \n",
        "    \n",
        "    \n",
        "    # base cases\n",
        "    if (check_purity(data)) or (len(data) < min_samples) or (counter == max_depth):\n",
        "        classification = classify_data(data)\n",
        "        \n",
        "        return classification\n",
        "\n",
        "    \n",
        "    # recursion\n",
        "    else:    \n",
        "        counter += 1\n",
        "\n",
        "        # helper functions \n",
        "        potential_splits = get_potential_splits(data)\n",
        "        split_column, split_value = determine_best_split(data, potential_splits)\n",
        "        data_below, data_above = split_data(data, split_column, split_value)\n",
        "        \n",
        "        # instantiate sub-tree\n",
        "        feature_name = COLUMN_HEADERS[split_column]\n",
        "        question = \"{} <= {}\".format(feature_name, split_value)\n",
        "        sub_tree = {question: []}\n",
        "        \n",
        "        # find answers (recursion)\n",
        "        yes_answer = decision_tree_algorithm(data_below, counter, min_samples, max_depth)\n",
        "        no_answer = decision_tree_algorithm(data_above, counter, min_samples, max_depth)\n",
        "        \n",
        "        # If the answers are the same, then there is no point in asking the question.\n",
        "        # This could happen when the data is classified even though it is not pure\n",
        "        # yet (min_samples or max_depth base cases).\n",
        "        if yes_answer == no_answer:\n",
        "            sub_tree = yes_answer\n",
        "        else:\n",
        "            sub_tree[question].append(yes_answer)\n",
        "            sub_tree[question].append(no_answer)\n",
        "        \n",
        "        return sub_tree"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTe_ap9d3pZQ"
      },
      "source": [
        "tree = decision_tree_algorithm(train_df,max_depth=10)\n",
        "#pprint(tree)"
      ],
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwG7KL9K3pkO"
      },
      "source": [
        "def classify(example, tree):            #classifying the datapoint using tree we constructed\n",
        "    question = list(tree.keys())[0]\n",
        "    feature_name, comparison_operator, value = question.split()\n",
        "\n",
        "    # ask question\n",
        "    if example[feature_name] <= float(value):\n",
        "        answer = tree[question][0]\n",
        "    else:\n",
        "        answer = tree[question][1]\n",
        "\n",
        "    # base case\n",
        "    if not isinstance(answer, dict):\n",
        "        return answer\n",
        "    \n",
        "    # recursive part\n",
        "    else:\n",
        "        residual_tree = answer\n",
        "        return classify(example, residual_tree)"
      ],
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqZ-2Tqs3ppc"
      },
      "source": [
        "# Accuracy\n",
        "def calculate_accuracy(df, tree):               #function to calculate overall accuracy\n",
        "\n",
        "    df[\"classification\"] = df.apply(classify, axis=1, args=(tree,))\n",
        "    df[\"classification_correct\"] = df[\"classification\"] == df[\"label\"]\n",
        "    \n",
        "    accuracy = df[\"classification_correct\"].mean()\n",
        "    \n",
        "    return accuracy"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXk918Nv3psK",
        "outputId": "2d08dd5a-37f4-450a-b09c-6a4fc80057bc"
      },
      "source": [
        "# Accuracy\n",
        "accuracy = calculate_accuracy(test_df, tree)      #printing accuracy\n",
        "print (\"accuracy: %.4f\" % accuracy )\n"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.8184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XBMLogO3pvb"
      },
      "source": [
        "# Writing results to a file (DO NOT CHANGE)\n",
        "f = open(myname+\"result.txt\", \"w\")\n",
        "f.write(\"accuracy: %.4f\" % accuracy)\n",
        "f.close()"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dpi3Lsb3pyP"
      },
      "source": [
        "#case for cross validation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zitFp5x3p0_"
      },
      "source": [
        "def splitDf(df, n) :\n",
        "    splitPoints = list(map( lambda x: int(x*len(df)/n), (list(range(1,n)))))     \n",
        "    splits = list(np.split(df.sample(frac=1), splitPoints))\n",
        "    return splits\n",
        "\n",
        "def makeTrainAndTest(splits, index) :\n",
        "   # index is zero based, so range 0-9 for 10 fold split\n",
        "   test = splits[index]\n",
        "\n",
        "   leftLst = splits[:index]\n",
        "   rightLst = splits[index+1:]\n",
        "\n",
        "   train = pd.concat(leftLst+rightLst)\n",
        "\n",
        "   return train, test"
      ],
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF9UnhOAERe4"
      },
      "source": [
        "df=pd.read_csv(\"/content/wine-dataset.csv\")\n",
        "df=df.rename(columns={\"quality\":\"label\"})\n",
        "n=10\n",
        "total_accuracy=0.0;\n",
        "splits=splitDf(df,n)\n",
        "for i in range(n):\n",
        "  train_set,test_set =makeTrainAndTest(splits, i)\n",
        "  tree = decision_tree_algorithm(train_set,max_depth=10)\n",
        "  accuracy = calculate_accuracy(test_set, tree) \n",
        "  total_accuracy=total_accuracy+accuracy\n",
        "\n",
        "total_accuracy=total_accuracy/10\n",
        "\n",
        "print (\"accuracy: %.4f\" % accuracy )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvWzhgOYERh6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZBRUrVTERpi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}